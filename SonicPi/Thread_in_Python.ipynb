{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CyW4m0g4Nwr"
      },
      "source": [
        "##Multithreading in Python\n",
        "\n",
        "Abbiamo visto a lezione che un processo è un programma in esecuzione, che più processi possono essere eseguiti in parallelo sullo stesso computer e che un processo a sua volta può avere thread multipli. \n",
        "\n",
        "Le differenze principali tra processi e thread sono:\n",
        "\n",
        "Avvio/terminazione sono operazioni meno costose per i thread \n",
        "I thread  richiedono meno risorse dei processi\n",
        "I processi non condividono la memoria mentre i thread condividono la stessa memoria virtuale e quindi richiedono particolari operazioni di sincronizzazione per evitare conflitti in lettura/scrittura\n",
        "\n",
        "Per quanto detto sopra il multithreading seppur potenzialmente pi efficiente grazie all'introduzione del parallelismo nell'esecuzione è  una tecnica di programmazione difficile da gestire. Questo  è particolarmente vero nel contesto di Python a causa del GIL, il lock globale dell'interprete.\n",
        "\n",
        "Il lock globale dell'interprete (GIL) è uno degli argomenti più controversi di Python. In CPython, l'implementazione più popolare di Python, il GIL è un mutex che forza l'esecuzione sequenziale del codice. Il GIL rende semplice l'integrazione di Python con librerie esterne che non sono thread-safe ed, in generale, rende il codice non-parallelo più veloce. Tuttavia, a causa di GIL, non possiamo realizzare il parallelismo vero tramite il multithreading. In sostanza, due thread nativi diversi dello stesso processo non possono eseguire il codice Python concorrentemente ma devono invece alternare l'esecuzione di loro blocchi di istruzioni nell'interprete (simulando quindi la concorrenza come nel multitasking).\n",
        "\n",
        "\n",
        "Ci sono casi in cui è ancora possibile eseguire cose in parallelo, \n",
        "ad esempio operazioni di I/O:\n",
        "\n",
        "\n",
        "Per questo motivo è possibile creare e lanciare thread in Python usando la libreria \"threading\": https://docs.python.org/3/library/threading.html#condition-objects\n",
        "\n",
        "Vediamo qualche esempio che poi riprenderemo in linguaggi come C e Java.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il seguente programma è un semplice programma di calcolo (CPU-bound) sequenziale"
      ],
      "metadata": {
        "id": "VTBcd9z1wAb7"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G28OE8Cz3rYP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c939055-0e5d-4f00-a2ca-4f635e9afea1"
      },
      "source": [
        "#CPU-bound sequential Python program \n",
        "\n",
        "COUNT = 50000000\n",
        "\n",
        "def countdown(n): \n",
        "  while n>0: n -= 1\n",
        "\n",
        "start = time.time()\n",
        "countdown(COUNT)\n",
        "end = time.time()\n",
        "\n",
        "print('Time taken in seconds -', end - start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken in seconds - 3.7248575687408447\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importiamo ora il modulo \"threading\" per creare due flussi di esecuzione spezzando in due parti parallele il calcolo."
      ],
      "metadata": {
        "id": "V7Kiu1-1wPOS"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unGiHUHL3vsL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57d4b302-3076-4eea-d40a-56487af7a3b5"
      },
      "source": [
        "#CPU-bound parallel Python program \n",
        "import time\n",
        "from threading import Thread\n",
        "\n",
        "COUNT = 50000000\n",
        "\n",
        "def countdown(n):\n",
        "  while n>0: n -= 1\n",
        "\n",
        "t1 = Thread(target=countdown, args=(COUNT//2,))\n",
        "t2 = Thread(target=countdown, args=(COUNT//2,))\n",
        "\n",
        "start = time.time()\n",
        "t1.start()\n",
        "t2.start()\n",
        "t1.join()\n",
        "t2.join()\n",
        "end = time.time()\n",
        "\n",
        "print('Time taken in seconds -', end - start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken in seconds - 3.742682695388794\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9b9Uj5wiHvD"
      },
      "source": [
        "A causa del GIL, l'interprete non riesce veramente a parallelizzare il calcolo ma è costretto ad alternare l'esecuzione delle istruzioni con effetto di appensantire invece che migliorare l'efficienza. Questo non è quindi un uso corretto del modulo threading di Python."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHzodM3M84Qj"
      },
      "source": [
        "\n",
        "La rimozione del GIL avrebbe reso Python 3 più lento rispetto a Python 2  single-thread.\n",
        "Tuttavia Python 3 ha apportato un notevole miglioramento al GIL della versione 2. Infatti Python 3 forza i thread a rilasciare il GIL dopo un intervallo fisso di utilizzo continuo della CPU.\n",
        "Inoltre è stato aggiunto un meccanismo per esaminare il numero di richieste di acquisizione del GIL da parte dei vari thread per evitare che sempre uno stesso thread mantenga il controllo della CPU (scheduler).\n",
        "Non tutti gli interpreti Python usano GIL. Ad esempio Jython, IronPython and PyPy, non includono questo meccanismo. Vediamo ora un esempio dove invece è sensato usare threading. Consideriamo una serie di operazioni di I/O ad esempio effettuare 4 richieste HTTP (anche dello stesso URL).\n",
        "\n",
        "Vediamo sotto un possibile codice sequenziale."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYQtX45ClZ98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b7d97cc-b755-4b95-c6dd-a434a5df1afe"
      },
      "source": [
        "import requests\n",
        "import time\n",
        "\n",
        "def download_site(url, session):\n",
        "    with session.get(url) as response:\n",
        "        print(f\"{len(response.content)}\")\n",
        "\n",
        "def download_all_sites(sites):\n",
        "    with requests.Session() as session:\n",
        "        for url in sites:\n",
        "            download_site(url, session)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    sites = [\"http://www.cython.org\"] * 4\n",
        "    start_time = time.time()\n",
        "    download_all_sites(sites)\n",
        "    duration = time.time() - start_time\n",
        "    print(f\"Downloaded {len(sites)} in {duration} seconds\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30474\n",
            "30474\n",
            "30474\n",
            "30474\n",
            "Downloaded 4 in 0.15180635452270508 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Introduciamo ora dei thread per eseguire in parallelo gli accessi HTTP (operazioni I/O)"
      ],
      "metadata": {
        "id": "4j9g66hE2Rov"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "051b3211-a682-48a5-f725-917c5d763874",
        "id": "k5buuGfc2JM3"
      },
      "source": [
        "import requests\n",
        "import time\n",
        "from threading import Thread\n",
        "\n",
        "url = \"http://www.cython.org\"\n",
        "\n",
        "t1 = Thread(target=countdown, args=(COUNT//2,))\n",
        "t2 = Thread(target=countdown, args=(COUNT//2,))\n",
        "\n",
        "def download_site(session):\n",
        "  with session.get(url) as response:\n",
        "    print(f\"{len(response.content)}\")      \n",
        "      \n",
        "with requests.Session() as session:\n",
        "  t1=Thread(target=download_site, args=(session,))\n",
        "  t2=Thread(target=download_site, args=(session,))\n",
        "  t3=Thread(target=download_site, args=(session,))\n",
        "  t4=Thread(target=download_site, args=(session,))\n",
        "  start = time.time()\n",
        "  t1.start()\n",
        "  t2.start()\n",
        "  t3.start()\n",
        "  t4.start()\n",
        "  t1.join()\n",
        "  t2.join()\n",
        "  t3.join()\n",
        "  t4.join()\n",
        "  end = time.time()\n",
        "  duration = end-start\n",
        "  print(f\"Downloaded in {duration} seconds\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30474\n",
            "30474\n",
            "30474\n",
            "30474\n",
            "Downloaded in 0.08198165893554688 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In questo caso trattandosi di operazioni di I/O che quindi non dipendono dal GIL, la loro esecuzione è veramente concorrente (e parallela nel numero di core della macchina) e quindi può portare a benefici in termini di efficienza."
      ],
      "metadata": {
        "id": "VegsHNcu4lNR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tra i vari meccanismi di comunicazione tra thread forniti da Python troviamo anche i Condition object. Sono oggetti che i thread possono usare per mettersi in attesa di notifiche da altri thread. Ad esempio un thread \"master\" potrebbe sincronizzare le operazioni di diversi thread slave, magari con diversa velocità, \n",
        "inviando di tanto in tanto messaggi di notifica come nel seguente esempio."
      ],
      "metadata": {
        "id": "M_528lMh6lHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random, time\n",
        "from threading import Thread, Condition\n",
        "\n",
        "def m(condition):\n",
        "  print(\"m\")\n",
        "  time.sleep(10000)\n",
        "  with condition:\n",
        "    condition.notifyAll() #Message to threads\n",
        "\n",
        "def s1(condition,stop_event):\n",
        "  with condition:\n",
        "    condition.wait() #Wait for message\n",
        "    print(\"s1\")\n",
        "\n",
        "def s2(condition,stop_event):\n",
        "  with condition:\n",
        "    condition.wait() #Wait for message\n",
        "    print(\"s2\")\n",
        "\n",
        "condition = Condition()\n",
        "th1 = Thread(name='master', target=m, args=(condition))\n",
        "th2 = Thread(name='s1', target=s1, args=(condition))\n",
        "th3 = Thread(name='s2', target=s2, args=(condition))\n",
        "\n",
        "th1.start()\n",
        "th2.start()\n",
        "th3.start()\n"
      ],
      "metadata": {
        "id": "EXDPk4a26lTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random, time\n",
        "from threading import Thread, Condition\n",
        "\n",
        "def m(condition):\n",
        "  print(\"m\")\n",
        "  with condition:\n",
        "    condition.notifyAll() #Message to threads\n",
        "\n",
        "def s1(condition):\n",
        "  with condition:\n",
        "    condition.wait() #Wait for message\n",
        "    print(\"s1\")\n",
        "\n",
        "def s2(condition):\n",
        "  with condition:\n",
        "    condition.wait() #Wait for message\n",
        "    print(\"s2\")\n",
        "\n",
        "condition = Condition()\n",
        "th1 = Thread(name='master', target=m, args=(condition,))\n",
        "th2 = Thread(name='s1', target=s1, args=(condition,))\n",
        "th3 = Thread(name='s2', target=s2, args=(condition,))\n",
        "\n",
        "th2.start()\n",
        "th3.start()\n",
        "time.sleep(0.5)\n",
        "th1.start()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEETyy1K940Z",
        "outputId": "e7775919-d794-4edc-a75a-2364164238ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "m\n",
            "s2\n",
            "s1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In questo esempio i thread th2 e th3 si fermano in attesa della notifica (inviata da th1 tramite notifyall) tramite il Condition object \"condition\" (che va interepretato come una sorta di canale di comunicazione). Quando th1 viene lanciato dopo la stampa di \"m\" manda la notifica che risveglia \"th2\" e \"th2\"\n",
        "\n",
        "Per maggiori approfondimenti sui Condition object: \n",
        "https://docs.python.org/3/library/threading.html#condition-objects"
      ],
      "metadata": {
        "id": "4n4QQgmj_Gjh"
      }
    }
  ]
}